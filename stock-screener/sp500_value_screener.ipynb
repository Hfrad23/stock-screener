{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500 Value Screener — Top 20 Stocks (5-Year Horizon)\n",
    "\n",
    "This notebook screens the entire S&P 500 and ranks stocks using a three-pillar composite score:\n",
    "\n",
    "| Pillar | Weight | What it measures |\n",
    "|---|---|---|\n",
    "| **DCF Margin of Safety** | 40% | Intrinsic value vs. current price (via discounted FCF) |\n",
    "| **Fundamental Ratios** | 35% | P/E, P/FCF, EV/EBITDA, P/B, PEG — sector-adjusted |\n",
    "| **Quality Score** | 25% | ROE, ROIC, debt levels, FCF consistency |\n",
    "\n",
    "**Designed for a 5-year investment horizon.**\n",
    "\n",
    "> **Runtime note:** Fetching data for ~500 stocks takes 10–20 minutes due to Yahoo Finance rate limits. Results are cached to `data/raw_data.pkl` so you can re-run analysis cells instantly after the first run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "# ── Plot style ──────────────────────────────────────────────────────────────\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': '#0f1117',\n",
    "    'axes.facecolor':   '#0f1117',\n",
    "    'axes.edgecolor':   '#333',\n",
    "    'axes.labelcolor':  '#ccc',\n",
    "    'xtick.color':      '#aaa',\n",
    "    'ytick.color':      '#aaa',\n",
    "    'text.color':       '#eee',\n",
    "    'grid.color':       '#222',\n",
    "    'grid.linestyle':   '--',\n",
    "    'font.family':      'DejaVu Sans',\n",
    "    'figure.dpi':       120,\n",
    "})\n",
    "sns.set_style('dark')\n",
    "\n",
    "# ── DCF Parameters ──────────────────────────────────────────────────────────\n",
    "WACC              = 0.10   # Discount rate (10% — reasonable all-in cost of capital)\n",
    "TERMINAL_GROWTH   = 0.03   # Long-run perpetual growth (≈ GDP growth)\n",
    "PROJECTION_YEARS  = 5      # Match the 5-year investment horizon\n",
    "MAX_FCF_GROWTH    = 0.25   # Cap bullish growth assumptions at 25% p.a.\n",
    "MIN_FCF_GROWTH    = -0.05  # Floor at -5% for declining businesses\n",
    "MARGIN_OF_SAFETY  = 0.20   # Only \"attractive\" if trading ≥20% below DCF value\n",
    "\n",
    "# ── Quality thresholds (minimum to pass quality gate) ───────────────────────\n",
    "MIN_ROE           = 0.05   # 5%  (relaxed to avoid excluding cyclicals unfairly)\n",
    "MIN_ROIC          = 0.04   # 4%\n",
    "MAX_DEBT_EQUITY   = 5.0    # Exclude extreme leverage\n",
    "\n",
    "# ── Scoring weights ──────────────────────────────────────────────────────────\n",
    "W_DCF             = 0.40\n",
    "W_FUNDAMENTALS    = 0.35\n",
    "W_QUALITY         = 0.25\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "print('✓ Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fetch S&P 500 Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500_tickers() -> pd.DataFrame:\n",
    "    \"\"\"Scrape S&P 500 constituents from Wikipedia.\"\"\"\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    resp = requests.get(url, timeout=15)\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df = df[['Symbol', 'Security', 'GICS Sector', 'GICS Sub-Industry']].copy()\n",
    "    df.columns = ['ticker', 'name', 'sector', 'industry']\n",
    "    # Yahoo Finance uses '-' instead of '.' for some tickers (e.g. BRK.B → BRK-B)\n",
    "    df['ticker'] = df['ticker'].str.replace('.', '-', regex=False)\n",
    "    return df\n",
    "\n",
    "sp500 = get_sp500_tickers()\n",
    "print(f'Loaded {len(sp500)} S&P 500 companies')\n",
    "print(f'Sectors: {sp500[\"sector\"].nunique()}')\n",
    "sp500.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fetch Fundamental Data from Yahoo Finance\n",
    "\n",
    "> **This cell takes ~10–20 minutes on first run.** Results are cached — skip to Cell 3 on subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_FILE = 'data/raw_data.pkl'\n",
    "FORCE_REFRESH = False   # Set True to re-download everything\n",
    "\n",
    "def safe_get(d, *keys, default=np.nan):\n",
    "    \"\"\"Safely traverse nested dict/Series.\"\"\"\n",
    "    for k in keys:\n",
    "        try:\n",
    "            if isinstance(d, dict):\n",
    "                d = d.get(k, default)\n",
    "            else:\n",
    "                d = d[k]\n",
    "        except (KeyError, TypeError, IndexError):\n",
    "            return default\n",
    "    return d if d is not None else default\n",
    "\n",
    "def extract_ttm_fcf(cashflow_df: pd.DataFrame) -> float:\n",
    "    \"\"\"Extract trailing twelve-month free cash flow.\"\"\"\n",
    "    if cashflow_df is None or cashflow_df.empty:\n",
    "        return np.nan\n",
    "    try:\n",
    "        # yfinance annual cashflow: rows = line items, cols = years\n",
    "        ocf_row = None\n",
    "        capex_row = None\n",
    "        for label in ['Operating Cash Flow', 'Total Cash From Operating Activities']:\n",
    "            if label in cashflow_df.index:\n",
    "                ocf_row = cashflow_df.loc[label]\n",
    "                break\n",
    "        for label in ['Capital Expenditure', 'Capital Expenditures']:\n",
    "            if label in cashflow_df.index:\n",
    "                capex_row = cashflow_df.loc[label]\n",
    "                break\n",
    "        if ocf_row is None:\n",
    "            return np.nan\n",
    "        ocf   = float(ocf_row.iloc[0])\n",
    "        capex = float(capex_row.iloc[0]) if capex_row is not None else 0.0\n",
    "        # capex is usually negative in yfinance; FCF = OCF + capex\n",
    "        return ocf + capex\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def fcf_growth_rate(cashflow_df: pd.DataFrame) -> float:\n",
    "    \"\"\"Compute 3-year FCF CAGR as growth estimate for DCF.\"\"\"\n",
    "    if cashflow_df is None or cashflow_df.empty:\n",
    "        return np.nan\n",
    "    try:\n",
    "        ocf_row = None\n",
    "        capex_row = None\n",
    "        for label in ['Operating Cash Flow', 'Total Cash From Operating Activities']:\n",
    "            if label in cashflow_df.index:\n",
    "                ocf_row = cashflow_df.loc[label]\n",
    "                break\n",
    "        for label in ['Capital Expenditure', 'Capital Expenditures']:\n",
    "            if label in cashflow_df.index:\n",
    "                capex_row = cashflow_df.loc[label]\n",
    "                break\n",
    "        if ocf_row is None or len(ocf_row) < 2:\n",
    "            return np.nan\n",
    "        ocf   = ocf_row.values.astype(float)\n",
    "        capex = capex_row.values.astype(float) if capex_row is not None else np.zeros(len(ocf))\n",
    "        fcf   = ocf + capex\n",
    "        n = min(len(fcf), 4)   # up to 4 years of history\n",
    "        start, end = fcf[n-1], fcf[0]\n",
    "        if start <= 0 or end <= 0:\n",
    "            return np.nan\n",
    "        return (end / start) ** (1 / (n - 1)) - 1\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def fetch_ticker_data(ticker: str) -> dict:\n",
    "    \"\"\"Fetch all needed data for a single ticker.\"\"\"\n",
    "    try:\n",
    "        t = yf.Ticker(ticker)\n",
    "        info = t.info or {}\n",
    "        cf   = t.cashflow          # annual cash-flow statement\n",
    "        bs   = t.balance_sheet     # annual balance sheet\n",
    "\n",
    "        price          = safe_get(info, 'currentPrice') or safe_get(info, 'regularMarketPrice')\n",
    "        market_cap     = safe_get(info, 'marketCap')\n",
    "        shares         = safe_get(info, 'sharesOutstanding')\n",
    "        pe             = safe_get(info, 'trailingPE')\n",
    "        pb             = safe_get(info, 'priceToBook')\n",
    "        peg            = safe_get(info, 'pegRatio')\n",
    "        ev_ebitda      = safe_get(info, 'enterpriseToEbitda')\n",
    "        roe            = safe_get(info, 'returnOnEquity')\n",
    "        roa            = safe_get(info, 'returnOnAssets')\n",
    "        debt_equity    = safe_get(info, 'debtToEquity')\n",
    "        total_debt     = safe_get(info, 'totalDebt')\n",
    "        cash           = safe_get(info, 'totalCash')\n",
    "        ev             = safe_get(info, 'enterpriseValue')\n",
    "        ebitda         = safe_get(info, 'ebitda')\n",
    "        revenue        = safe_get(info, 'totalRevenue')\n",
    "        eps_fwd        = safe_get(info, 'forwardEps')\n",
    "        revenue_growth = safe_get(info, 'revenueGrowth')\n",
    "        earnings_growth= safe_get(info, 'earningsGrowth')\n",
    "        gross_margins  = safe_get(info, 'grossMargins')\n",
    "        op_margins     = safe_get(info, 'operatingMargins')\n",
    "        profit_margins = safe_get(info, 'profitMargins')\n",
    "\n",
    "        # FCF from cash flow statement\n",
    "        ttm_fcf   = extract_ttm_fcf(cf)\n",
    "        fcf_growh = fcf_growth_rate(cf)\n",
    "\n",
    "        # P/FCF\n",
    "        p_fcf = np.nan\n",
    "        if market_cap and ttm_fcf and ttm_fcf > 0:\n",
    "            p_fcf = market_cap / ttm_fcf\n",
    "\n",
    "        # ROIC proxy: EBIT*(1-tax) / (total_debt + equity)\n",
    "        roic = np.nan\n",
    "        try:\n",
    "            ebit = safe_get(info, 'ebit')\n",
    "            tax_rate = safe_get(info, 'effectiveTaxRate', default=0.21)\n",
    "            equity = safe_get(info, 'bookValue')\n",
    "            if shares and equity:\n",
    "                equity_total = equity * shares\n",
    "            else:\n",
    "                equity_total = np.nan\n",
    "            if ebit and equity_total and not np.isnan(equity_total):\n",
    "                invested_cap = (total_debt or 0) + equity_total\n",
    "                if invested_cap > 0:\n",
    "                    roic = ebit * (1 - (tax_rate or 0.21)) / invested_cap\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return {\n",
    "            'ticker':          ticker,\n",
    "            'price':           price,\n",
    "            'market_cap':      market_cap,\n",
    "            'shares':          shares,\n",
    "            'pe':              pe,\n",
    "            'pb':              pb,\n",
    "            'peg':             peg,\n",
    "            'ev_ebitda':       ev_ebitda,\n",
    "            'p_fcf':           p_fcf,\n",
    "            'roe':             roe,\n",
    "            'roa':             roa,\n",
    "            'roic':            roic,\n",
    "            'debt_equity':     debt_equity,\n",
    "            'total_debt':      total_debt,\n",
    "            'cash':            cash,\n",
    "            'ev':              ev,\n",
    "            'ebitda':          ebitda,\n",
    "            'revenue':         revenue,\n",
    "            'ttm_fcf':         ttm_fcf,\n",
    "            'fcf_growth':      fcf_growh,\n",
    "            'revenue_growth':  revenue_growth,\n",
    "            'earnings_growth': earnings_growth,\n",
    "            'gross_margins':   gross_margins,\n",
    "            'op_margins':      op_margins,\n",
    "            'profit_margins':  profit_margins,\n",
    "            'eps_fwd':         eps_fwd,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'ticker': ticker, 'error': str(e)}\n",
    "\n",
    "# ── Main fetch loop ──────────────────────────────────────────────────────────\n",
    "if os.path.exists(CACHE_FILE) and not FORCE_REFRESH:\n",
    "    with open(CACHE_FILE, 'rb') as f:\n",
    "        raw_records = pickle.load(f)\n",
    "    print(f'✓ Loaded cached data ({len(raw_records)} records). Set FORCE_REFRESH=True to re-download.')\n",
    "else:\n",
    "    print(f'Fetching data for {len(sp500)} tickers from Yahoo Finance...')\n",
    "    print('  This will take ~15 minutes. Progress is saved — restart is safe.\\n')\n",
    "    raw_records = []\n",
    "    tickers = sp500['ticker'].tolist()\n",
    "\n",
    "    for i, ticker in enumerate(tqdm(tickers, desc='Fetching')):\n",
    "        rec = fetch_ticker_data(ticker)\n",
    "        raw_records.append(rec)\n",
    "        # Polite delay to avoid rate-limiting (1 req/sec on average)\n",
    "        time.sleep(0.8)\n",
    "        # Checkpoint every 50 tickers\n",
    "        if (i + 1) % 50 == 0:\n",
    "            with open(CACHE_FILE, 'wb') as f:\n",
    "                pickle.dump(raw_records, f)\n",
    "\n",
    "    with open(CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump(raw_records, f)\n",
    "    print(f'\\n✓ Done. Data cached to {CACHE_FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the Master DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame(raw_records)\n",
    "\n",
    "# Merge with sector/name metadata\n",
    "df = df_raw.merge(sp500, on='ticker', how='left')\n",
    "\n",
    "# Drop tickers with critical missing data\n",
    "df = df[df['price'].notna() & df['market_cap'].notna()]\n",
    "df = df[~df.get('error', pd.Series(dtype=str)).notna() if 'error' in df.columns else df.index]\n",
    "\n",
    "# Ensure numeric types\n",
    "numeric_cols = ['pe', 'pb', 'peg', 'ev_ebitda', 'p_fcf', 'roe', 'roa',\n",
    "                'roic', 'debt_equity', 'ttm_fcf', 'fcf_growth',\n",
    "                'revenue_growth', 'earnings_growth', 'gross_margins',\n",
    "                'op_margins', 'profit_margins', 'price', 'market_cap']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# debt_equity from yfinance is sometimes in % form (e.g. 45.3 = 45.3%)\n",
    "# normalise to ratio form if values are very large\n",
    "if df['debt_equity'].median() > 10:\n",
    "    df['debt_equity'] = df['debt_equity'] / 100\n",
    "\n",
    "print(f'Universe after cleaning: {len(df)} stocks')\n",
    "print(f'\\nData coverage (non-null %):')\n",
    "coverage = df[numeric_cols].notna().mean().sort_values(ascending=False)\n",
    "for col, pct in coverage.items():\n",
    "    bar = '█' * int(pct * 20)\n",
    "    print(f'  {col:<18} {bar:<20} {pct:.0%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DCF Valuation\n",
    "\n",
    "**Model:**\n",
    "1. Start with trailing FCF per share\n",
    "2. Grow at the company's historical FCF CAGR (capped at ±25%/year) for 5 years\n",
    "3. Apply a terminal value using the Gordon Growth Model (3% perpetual growth)\n",
    "4. Discount all cash flows at 10% WACC\n",
    "5. Add net cash (cash − debt) per share\n",
    "6. **Margin of safety** = (intrinsic value − price) / intrinsic value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dcf(row: pd.Series) -> dict:\n",
    "    \"\"\"Return intrinsic value per share and margin of safety for one stock.\"\"\"\n",
    "    result = {'dcf_value': np.nan, 'margin_of_safety': np.nan}\n",
    "\n",
    "    fcf        = row.get('ttm_fcf')\n",
    "    shares     = row.get('shares')\n",
    "    price      = row.get('price')\n",
    "    fcf_g      = row.get('fcf_growth')\n",
    "    cash       = row.get('cash') or 0\n",
    "    total_debt = row.get('total_debt') or 0\n",
    "\n",
    "    # Need positive FCF, share count, and price\n",
    "    if any(pd.isna(x) for x in [fcf, shares, price]):\n",
    "        return result\n",
    "    if shares <= 0 or price <= 0 or fcf <= 0:\n",
    "        return result\n",
    "\n",
    "    # Growth rate: use historical FCF CAGR, fall back to 5% if unavailable\n",
    "    if pd.isna(fcf_g):\n",
    "        fcf_g = 0.05\n",
    "    g = np.clip(fcf_g, MIN_FCF_GROWTH, MAX_FCF_GROWTH)\n",
    "\n",
    "    # Project FCF for PROJECTION_YEARS\n",
    "    pv_sum = 0.0\n",
    "    for yr in range(1, PROJECTION_YEARS + 1):\n",
    "        projected_fcf = fcf * (1 + g) ** yr\n",
    "        pv_sum += projected_fcf / (1 + WACC) ** yr\n",
    "\n",
    "    # Terminal value (Gordon Growth at end of projection period)\n",
    "    terminal_fcf = fcf * (1 + g) ** PROJECTION_YEARS * (1 + TERMINAL_GROWTH)\n",
    "    terminal_val = terminal_fcf / (WACC - TERMINAL_GROWTH)\n",
    "    pv_terminal  = terminal_val / (1 + WACC) ** PROJECTION_YEARS\n",
    "\n",
    "    # Enterprise value → equity value\n",
    "    equity_value = pv_sum + pv_terminal + cash - total_debt\n",
    "    if equity_value <= 0:\n",
    "        return result\n",
    "\n",
    "    intrinsic_value = equity_value / shares\n",
    "    mos = (intrinsic_value - price) / intrinsic_value\n",
    "\n",
    "    result['dcf_value']         = round(intrinsic_value, 2)\n",
    "    result['margin_of_safety']  = round(mos, 4)\n",
    "    return result\n",
    "\n",
    "dcf_results = df.apply(run_dcf, axis=1, result_type='expand')\n",
    "df = pd.concat([df, dcf_results], axis=1)\n",
    "\n",
    "dcf_valid = df['margin_of_safety'].notna().sum()\n",
    "undervalued = (df['margin_of_safety'] >= MARGIN_OF_SAFETY).sum()\n",
    "print(f'DCF computed for {dcf_valid} stocks')\n",
    "print(f'Stocks trading ≥{MARGIN_OF_SAFETY:.0%} below DCF value: {undervalued}')\n",
    "\n",
    "# Sanity-check sample\n",
    "df[['ticker','name','price','dcf_value','margin_of_safety']].dropna().sort_values(\n",
    "    'margin_of_safety', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Composite Scoring\n",
    "\n",
    "Each metric is percentile-ranked **within its GICS sector** (so Financials are compared to Financials, Tech to Tech, etc.) to avoid penalising sectors that structurally carry different valuations.\n",
    "\n",
    "For each metric, the ranking direction is set so that **higher score = more attractive**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_rank_sector(series: pd.Series, sector: pd.Series,\n",
    "                            ascending: bool = True) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rank each value within its sector group.\n",
    "    ascending=True  → lower value is better (e.g. P/E)\n",
    "    ascending=False → higher value is better (e.g. ROE)\n",
    "    Returns a 0-1 percentile score where 1.0 = most attractive.\n",
    "    \"\"\"\n",
    "    result = pd.Series(np.nan, index=series.index)\n",
    "    for sec in sector.unique():\n",
    "        mask = sector == sec\n",
    "        sub  = series[mask]\n",
    "        valid = sub.notna()\n",
    "        if valid.sum() < 3:\n",
    "            continue\n",
    "        ranked = sub[valid].rank(pct=True, ascending=ascending)\n",
    "        # ascending=True means low value → high rank (good), which is what we want\n",
    "        # But rank(ascending=True) gives LOW values a LOW rank.\n",
    "        # Flip: if lower is better, we want low values to score 1.0\n",
    "        if ascending:  # lower metric = better\n",
    "            result[valid & mask] = 1 - ranked + ranked.min()\n",
    "        else:          # higher metric = better\n",
    "            result[valid & mask] = ranked\n",
    "    # Normalise to [0, 1]\n",
    "    mn, mx = result.min(), result.max()\n",
    "    if mx > mn:\n",
    "        result = (result - mn) / (mx - mn)\n",
    "    return result\n",
    "\n",
    "sector = df['sector'].fillna('Unknown')\n",
    "\n",
    "# ── Valuation sub-scores (lower = better → ascending=True) ──────────────────\n",
    "df['score_pe']       = percentile_rank_sector(df['pe'].clip(0, 100),      sector, ascending=True)\n",
    "df['score_pfcf']     = percentile_rank_sector(df['p_fcf'].clip(0, 150),   sector, ascending=True)\n",
    "df['score_ev_ebitda']= percentile_rank_sector(df['ev_ebitda'].clip(0, 60),sector, ascending=True)\n",
    "df['score_pb']       = percentile_rank_sector(df['pb'].clip(0, 20),       sector, ascending=True)\n",
    "df['score_peg']      = percentile_rank_sector(df['peg'].clip(0, 5),       sector, ascending=True)\n",
    "\n",
    "# Composite fundamental score (equal-weight the available metrics)\n",
    "fund_cols = ['score_pe', 'score_pfcf', 'score_ev_ebitda', 'score_pb', 'score_peg']\n",
    "df['fund_score'] = df[fund_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "# ── Quality sub-scores (higher = better) ────────────────────────────────────\n",
    "df['score_roe']       = percentile_rank_sector(df['roe'].clip(-0.5, 1),    sector, ascending=False)\n",
    "df['score_roic']      = percentile_rank_sector(df['roic'].clip(-0.5, 1),   sector, ascending=False)\n",
    "df['score_op_margin'] = percentile_rank_sector(df['op_margins'].clip(-1,1),sector, ascending=False)\n",
    "df['score_low_debt']  = percentile_rank_sector(df['debt_equity'].clip(0,10),sector, ascending=True)\n",
    "df['score_fcf_pos']   = (df['ttm_fcf'] > 0).astype(float)  # Binary: positive FCF = 1\n",
    "\n",
    "qual_cols = ['score_roe', 'score_roic', 'score_op_margin', 'score_low_debt', 'score_fcf_pos']\n",
    "df['qual_score'] = df[qual_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "# ── DCF score ────────────────────────────────────────────────────────────────\n",
    "# Clip MoS to [-1, 1] so extreme outliers don't dominate\n",
    "mos_clipped = df['margin_of_safety'].clip(-1.0, 1.0)\n",
    "# Shift to [0, 1] (0 = fully overvalued, 1 = maximum discount)\n",
    "df['dcf_score'] = (mos_clipped + 1) / 2\n",
    "df['dcf_score'] = df['dcf_score'].fillna(0.5)  # neutral for stocks without DCF\n",
    "\n",
    "# ── Composite ────────────────────────────────────────────────────────────────\n",
    "df['composite_score'] = (\n",
    "    W_DCF          * df['dcf_score'] +\n",
    "    W_FUNDAMENTALS * df['fund_score'] +\n",
    "    W_QUALITY      * df['qual_score']\n",
    ")\n",
    "\n",
    "print('Scoring complete.')\n",
    "print(f'\\nScore distribution:')\n",
    "print(df[['dcf_score', 'fund_score', 'qual_score', 'composite_score']].describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apply Quality Gate & Rank the Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum quality requirements to be considered\n",
    "quality_gate = (\n",
    "    (df['roe'].fillna(0)         >= MIN_ROE) &\n",
    "    (df['roic'].fillna(0)        >= MIN_ROIC) &\n",
    "    (df['debt_equity'].fillna(99) <= MAX_DEBT_EQUITY) &\n",
    "    (df['ttm_fcf'].fillna(-1)    > 0) &\n",
    "    (df['pe'].fillna(0)          > 0)  # must be profitable\n",
    ")\n",
    "\n",
    "df_qualified = df[quality_gate].copy()\n",
    "print(f'Stocks passing quality gate: {len(df_qualified)} / {len(df)}')\n",
    "\n",
    "# Final ranking\n",
    "df_ranked = df_qualified.sort_values('composite_score', ascending=False).reset_index(drop=True)\n",
    "df_ranked['rank'] = df_ranked.index + 1\n",
    "\n",
    "# Top 20\n",
    "top20 = df_ranked.head(20).copy()\n",
    "\n",
    "display_cols = [\n",
    "    'rank', 'ticker', 'name', 'sector',\n",
    "    'price', 'dcf_value', 'margin_of_safety',\n",
    "    'pe', 'p_fcf', 'ev_ebitda', 'pb', 'peg',\n",
    "    'roe', 'roic', 'debt_equity',\n",
    "    'dcf_score', 'fund_score', 'qual_score', 'composite_score'\n",
    "]\n",
    "\n",
    "available_cols = [c for c in display_cols if c in top20.columns]\n",
    "top20_display = top20[available_cols].copy()\n",
    "\n",
    "# Format for readability\n",
    "pct_cols = ['margin_of_safety', 'roe', 'roic']\n",
    "for c in pct_cols:\n",
    "    if c in top20_display.columns:\n",
    "        top20_display[c] = top20_display[c].map(lambda x: f'{x:.1%}' if pd.notna(x) else '—')\n",
    "\n",
    "ratio_cols = ['pe', 'p_fcf', 'ev_ebitda', 'pb', 'peg', 'debt_equity']\n",
    "for c in ratio_cols:\n",
    "    if c in top20_display.columns:\n",
    "        top20_display[c] = top20_display[c].map(lambda x: f'{x:.1f}' if pd.notna(x) else '—')\n",
    "\n",
    "score_cols = ['dcf_score', 'fund_score', 'qual_score', 'composite_score']\n",
    "for c in score_cols:\n",
    "    if c in top20_display.columns:\n",
    "        top20_display[c] = top20_display[c].map(lambda x: f'{x:.3f}' if pd.notna(x) else '—')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "display(top20_display)\n",
    "\n",
    "# Save to CSV\n",
    "top20.to_csv('output/top20_value_stocks.csv', index=False)\n",
    "df_ranked.to_csv('output/full_ranking.csv', index=False)\n",
    "print('\\n✓ Results saved to output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Chart 1: Top 20 Composite Scores ────────────────────────────────────────\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "colors = plt.cm.YlOrRd(np.linspace(0.4, 0.9, len(top20)))\n",
    "bars = ax.barh(\n",
    "    top20['ticker'][::-1],\n",
    "    top20['composite_score'][::-1],\n",
    "    color=colors[::-1],\n",
    "    edgecolor='none',\n",
    "    height=0.7\n",
    ")\n",
    "\n",
    "# Annotate with scores\n",
    "for bar, (_, row) in zip(bars, top20[::-1].iterrows()):\n",
    "    ax.text(bar.get_width() + 0.002, bar.get_y() + bar.get_height()/2,\n",
    "            f'{row[\"composite_score\"]:.3f}',\n",
    "            va='center', ha='left', fontsize=8, color='#aaa')\n",
    "\n",
    "ax.set_xlabel('Composite Score (higher = more attractive)', fontsize=11)\n",
    "ax.set_title('Top 20 S&P 500 Value Stocks — 5-Year Horizon', fontsize=14, pad=15)\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/top20_scores.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Chart 2: Score Breakdown (stacked bar) ───────────────────────────────────\n",
    "fig, ax = plt.subplots(figsize=(13, 7))\n",
    "\n",
    "tickers   = top20['ticker'].tolist()\n",
    "dcf_vals  = (top20['dcf_score']   * W_DCF).tolist()\n",
    "fund_vals = (top20['fund_score']  * W_FUNDAMENTALS).tolist()\n",
    "qual_vals = (top20['qual_score']  * W_QUALITY).tolist()\n",
    "\n",
    "x = np.arange(len(tickers))\n",
    "w = 0.65\n",
    "\n",
    "b1 = ax.bar(x, dcf_vals,  width=w, label=f'DCF ({W_DCF:.0%})',           color='#e67e22')\n",
    "b2 = ax.bar(x, fund_vals, width=w, bottom=dcf_vals,\n",
    "            label=f'Fundamentals ({W_FUNDAMENTALS:.0%})',                  color='#3498db')\n",
    "b3 = ax.bar(x, qual_vals, width=w,\n",
    "            bottom=[d+f for d,f in zip(dcf_vals, fund_vals)],\n",
    "            label=f'Quality ({W_QUALITY:.0%})',                            color='#2ecc71')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(tickers, rotation=45, ha='right', fontsize=9)\n",
    "ax.set_ylabel('Weighted Score Contribution')\n",
    "ax.set_title('Score Breakdown by Pillar — Top 20', fontsize=13, pad=12)\n",
    "ax.legend(loc='upper right', framealpha=0.2)\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/score_breakdown.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Chart 3: Price vs. DCF Intrinsic Value ───────────────────────────────────\n",
    "plot_df = top20[top20['dcf_value'].notna()].copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(plot_df))\n",
    "w = 0.35\n",
    "\n",
    "ax.bar(x - w/2, plot_df['price'],     width=w, label='Current Price',   color='#3498db', alpha=0.85)\n",
    "ax.bar(x + w/2, plot_df['dcf_value'], width=w, label='DCF Intrinsic Value', color='#e67e22', alpha=0.85)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(plot_df['ticker'], rotation=45, ha='right', fontsize=9)\n",
    "ax.set_ylabel('Price ($)')\n",
    "ax.set_title('Current Price vs. DCF Intrinsic Value — Top 20', fontsize=13, pad=12)\n",
    "ax.legend(framealpha=0.2)\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/price_vs_dcf.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Chart 4: Sector Distribution ─────────────────────────────────────────────\n",
    "sector_counts = top20['sector'].value_counts()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "palette = sns.color_palette('husl', len(sector_counts))\n",
    "ax1.pie(sector_counts.values, labels=sector_counts.index,\n",
    "        colors=palette, autopct='%1.0f%%', startangle=90,\n",
    "        textprops={'fontsize': 9})\n",
    "ax1.set_title('Top 20 — Sector Breakdown', fontsize=12)\n",
    "\n",
    "# Scatter: Quality vs. Valuation coloured by DCF MoS\n",
    "scatter_df = df_qualified.dropna(subset=['fund_score', 'qual_score', 'margin_of_safety'])\n",
    "sc = ax2.scatter(\n",
    "    scatter_df['fund_score'],\n",
    "    scatter_df['qual_score'],\n",
    "    c=scatter_df['margin_of_safety'].clip(-0.5, 1),\n",
    "    cmap='RdYlGn',\n",
    "    alpha=0.5, s=20\n",
    ")\n",
    "# Highlight top 20\n",
    "ax2.scatter(top20['fund_score'], top20['qual_score'],\n",
    "            color='gold', s=80, zorder=5, label='Top 20', edgecolors='white', linewidth=0.5)\n",
    "for _, row in top20.iterrows():\n",
    "    ax2.annotate(row['ticker'], (row['fund_score'], row['qual_score']),\n",
    "                 fontsize=6.5, color='white', alpha=0.9,\n",
    "                 xytext=(3, 3), textcoords='offset points')\n",
    "\n",
    "plt.colorbar(sc, ax=ax2, label='DCF Margin of Safety')\n",
    "ax2.set_xlabel('Fundamental Score (Valuation)')\n",
    "ax2.set_ylabel('Quality Score')\n",
    "ax2.set_title('Quality vs. Valuation (S&P 500 universe)', fontsize=12)\n",
    "ax2.legend(framealpha=0.2, fontsize=8)\n",
    "ax2.spines[['top','right']].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/sector_and_scatter.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Chart 5: Key Valuation Ratios Heatmap ────────────────────────────────────\n",
    "heatmap_cols = ['pe', 'p_fcf', 'ev_ebitda', 'pb', 'peg']\n",
    "heatmap_df = top20.set_index('ticker')[heatmap_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Normalise each column to [0, 1] for colour (lower = greener = better)\n",
    "norm_df = heatmap_df.copy()\n",
    "for col in heatmap_cols:\n",
    "    mn, mx = norm_df[col].min(), norm_df[col].max()\n",
    "    if mx > mn:\n",
    "        norm_df[col] = 1 - (norm_df[col] - mn) / (mx - mn)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "sns.heatmap(\n",
    "    norm_df,\n",
    "    annot=heatmap_df.round(1),\n",
    "    fmt='.1f',\n",
    "    cmap='RdYlGn',\n",
    "    linewidths=0.5,\n",
    "    linecolor='#222',\n",
    "    ax=ax,\n",
    "    cbar=False,\n",
    "    annot_kws={'size': 9}\n",
    ")\n",
    "ax.set_title('Valuation Ratios — Top 20 Stocks (Green = Cheaper)', fontsize=12, pad=10)\n",
    "ax.set_xlabel('')\n",
    "ax.set_xticklabels(['P/E', 'P/FCF', 'EV/EBITDA', 'P/B', 'PEG'], fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/ratios_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 70)\n",
    "print('  S&P 500 VALUE SCREENER — TOP 20 STOCKS (5-YEAR HORIZON)')\n",
    "print(f'  Run date: {datetime.today().strftime(\"%B %d, %Y\")}')\n",
    "print('=' * 70)\n",
    "print()\n",
    "print(f'  Universe scanned:  {len(df)} S&P 500 companies')\n",
    "print(f'  Passed quality gate: {len(df_qualified)}')\n",
    "print()\n",
    "print('  Scoring weights:')\n",
    "print(f'    DCF margin of safety  {W_DCF:.0%}')\n",
    "print(f'    Fundamental ratios    {W_FUNDAMENTALS:.0%}')\n",
    "print(f'    Quality (ROE/ROIC)    {W_QUALITY:.0%}')\n",
    "print()\n",
    "print('  DCF assumptions:')\n",
    "print(f'    Discount rate (WACC)  {WACC:.0%}')\n",
    "print(f'    Terminal growth rate  {TERMINAL_GROWTH:.0%}')\n",
    "print(f'    Projection horizon    {PROJECTION_YEARS} years')\n",
    "print(f'    FCF growth cap        {MAX_FCF_GROWTH:.0%} / {MIN_FCF_GROWTH:.0%}')\n",
    "print()\n",
    "print('-' * 70)\n",
    "print(f'  {\"#\":<4} {\"Ticker\":<8} {\"Company\":<28} {\"Sector\":<22} {\"Score\"}')\n",
    "print('-' * 70)\n",
    "for _, row in top20.iterrows():\n",
    "    name_trunc = str(row.get('name', ''))[:27]\n",
    "    sector_trunc = str(row.get('sector', ''))[:21]\n",
    "    print(f'  {int(row[\"rank\"]):<4} {row[\"ticker\"]:<8} {name_trunc:<28} {sector_trunc:<22} {row[\"composite_score\"]:.4f}')\n",
    "print('-' * 70)\n",
    "print()\n",
    "print('  Files saved:')\n",
    "print('    output/top20_value_stocks.csv   — Full data for top 20')\n",
    "print('    output/full_ranking.csv         — All qualified stocks ranked')\n",
    "print('    output/top20_scores.png         — Bar chart of composite scores')\n",
    "print('    output/score_breakdown.png      — Pillar contribution breakdown')\n",
    "print('    output/price_vs_dcf.png         — Price vs. intrinsic value')\n",
    "print('    output/sector_and_scatter.png   — Sector pie + quality/value scatter')\n",
    "print('    output/ratios_heatmap.png       — Valuation ratios heatmap')\n",
    "print()\n",
    "print('  ⚠  DISCLAIMER: This is a quantitative screening tool, not financial')\n",
    "print('     advice. Always conduct your own due diligence before investing.')\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tweak the Model (Optional)\n",
    "\n",
    "Run the cell below to quickly re-rank with different weights — no re-downloading needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Re-rank with custom weights ──────────────────────────────────────────────\n",
    "# Change these and re-run this cell:\n",
    "CUSTOM_W_DCF          = 0.40\n",
    "CUSTOM_W_FUNDAMENTALS = 0.35\n",
    "CUSTOM_W_QUALITY      = 0.25\n",
    "\n",
    "assert abs(CUSTOM_W_DCF + CUSTOM_W_FUNDAMENTALS + CUSTOM_W_QUALITY - 1.0) < 1e-9, \\\n",
    "    'Weights must sum to 1.0'\n",
    "\n",
    "df_qualified['custom_score'] = (\n",
    "    CUSTOM_W_DCF          * df_qualified['dcf_score'] +\n",
    "    CUSTOM_W_FUNDAMENTALS * df_qualified['fund_score'] +\n",
    "    CUSTOM_W_QUALITY      * df_qualified['qual_score']\n",
    ")\n",
    "\n",
    "custom_top20 = df_qualified.sort_values('custom_score', ascending=False).head(20)\n",
    "\n",
    "print(f'Top 20 with weights DCF={CUSTOM_W_DCF:.0%}  Fund={CUSTOM_W_FUNDAMENTALS:.0%}  Quality={CUSTOM_W_QUALITY:.0%}')\n",
    "print()\n",
    "for i, (_, row) in enumerate(custom_top20.iterrows(), 1):\n",
    "    name_trunc = str(row.get('name', ''))[:28]\n",
    "    print(f'  {i:<3} {row[\"ticker\"]:<8} {name_trunc:<30} {row[\"custom_score\"]:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
